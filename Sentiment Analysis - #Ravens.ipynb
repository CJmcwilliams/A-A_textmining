{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire and Analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "For my Acquire and Analyze project, I thought it would be interesting to analyze the sentiment of an NFL team's hashtag during the course of a game. I chose the Baltimore Ravens because they are an exciting team to watch. I started out by pulling all of the tweets that included #Ravens from Twitter during the Sunday Night Football game between the Ravens and the Patriots on 11/16/20. I quickly realized that it would be better to have two games rather than one. So I also pulled all the tweets that included #Ravens again for the following week. The Ravens next opponent was the Tennessee Titans.\n",
    "\n",
    "Since I am only analyzing the tweets happening during the game, the sentiment of the tweets should follow the flow of the game. So when the Ravens score or make a stop on defense, the sentiment should be positive. If the team the Ravens are playing scores or the Ravens do something bad, the sentiment should be negative.\n",
    "\n",
    "To help the viewer have a better grasp of what happened during the game, the scoring summary will be provided. Then the sentiment scores for each game with be plotted. We will then look to see how our plot of sentiment scores compares to the win probability chart that ESPN calculates in real-time during the game. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the libraries I'll need\n",
    "import nltk\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sentiment analysis\n",
    "import random\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Up Process\n",
    "\n",
    "The dataset I have collected must be cleaned up. To start, I pulled the two columns of the dataset that I needed:\n",
    "\n",
    "1) Text in the tweet\n",
    "    - Tokenization\n",
    "    - Normalization\n",
    "\n",
    "2) Time of tweet\n",
    "    - I had to use the datetime package to strip year, month, day, hour, minute, and second.\n",
    "    - It makes the times of the tweets way easier to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, loading in the data from the Ravens vs. Patriots game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading in the text file with the data from Twitter\n",
    "#grabbing the text of the tweet and time and putting them in a list\n",
    "balt =[]\n",
    "\n",
    "with open(\"#Ravens_followerss.txt\",'r') as infile :\n",
    "    next(infile)\n",
    "    for idx, line in enumerate(infile.readlines()) :\n",
    "        tweet_text = line.strip().split(\"\\t\")[-1]\n",
    "        #tweet_text = tweet_text.lower().split()\n",
    "        #tweet_text = [s.translate(str.maketrans('', '', string.punctuation)) for s in tweet_text]\n",
    "        time = line.strip().split(\"\\t\")[-2]\n",
    "        time = datetime.datetime.strptime(time,\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        pair = (time, tweet_text)\n",
    "        balt.append(pair)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the same process for the next game where the Ravens played the Titans. There is probably a more efficient way to do this, but I chose to stick with what works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "balt_vs_Titans =[]\n",
    "\n",
    "with open(\"#Ravens_game2_redo.txt\",'r') as infile :\n",
    "    next(infile)\n",
    "    for idx, line in enumerate(infile.readlines()) :\n",
    "        tweet_text = line.strip().split(\"\\t\")[-1]\n",
    "        #tweet_text = tweet_text.lower().split()\n",
    "        #tweet_text = [s.translate(str.maketrans('', '', string.punctuation)) for s in tweet_text]\n",
    "        time = line.strip().split(\"\\t\")[-2]\n",
    "        time = datetime.datetime.strptime(time,\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        pairs = (time, tweet_text)\n",
    "        balt_vs_Titans.append(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting Tweets not during the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still one problem with the data that needs to be addressed. The Twitter pull for this data wasn't perfect, and it ended up pulling tweets from before the game and after the game. I want to only analyze the sentiment during the game, so the next step is to delete the tweets that fall outside of the time frame of the game. \n",
    "\n",
    "All of Twitter's data uses Coordinated Universal Time (UTC). Mountain Standard Time is five hours ahead of UTC. The Sunday Night Game when the Ravens played the Patriots started around 6:24 P.M. Mountain Standard Time. So this means the data for the game would start at 1:24 P.M. UTC. Same thing for the end of the game.\n",
    "\n",
    "The same idea applies for the next game as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the start time and end time\n",
    "game_start = datetime.datetime.strptime(\"2020-11-16 01:24:00\",\"%Y-%m-%d %H:%M:%S\")\n",
    "game_end = datetime.datetime.strptime(\"2020-11-16 04:20:00\",\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "test_1 = datetime.datetime.strptime(\"2020-11-16 01:00:00\",\"%Y-%m-%d %H:%M:%S\")\n",
    "test_2 = datetime.datetime.strptime(\"2020-11-16 03:00:00\",\"%Y-%m-%d %H:%M:%S\")\n",
    "test_3 = datetime.datetime.strptime(\"2020-11-16 06:00:00\",\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "#making sure the code works\n",
    "assert(test_1 < game_start)\n",
    "assert(game_start < test_2 and test_2 < game_end)\n",
    "assert(game_end < test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating game_tweets to hold all the tweets that happened during the game\n",
    "game_tweets = []\n",
    "\n",
    "for pair in balt :\n",
    "    time = pair[0]\n",
    "    if (time > game_start and time < game_end) :\n",
    "        game_tweets.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ordering the list of tuples by date\n",
    "#this makes it go from beginning to end (instead of end to beginning)\n",
    "game_tweets = sorted(game_tweets, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now for the next game\n",
    "\n",
    "#Saving the start time and end time\n",
    "game_start_22nd = datetime.datetime.strptime(\"2020-11-22 17:55:00\",\"%Y-%m-%d %H:%M:%S\")\n",
    "game_end_22nd = datetime.datetime.strptime(\"2020-11-22 21:22:00\",\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "test_1 = datetime.datetime.strptime(\"2020-11-22 16:00:00\",\"%Y-%m-%d %H:%M:%S\")\n",
    "test_2 = datetime.datetime.strptime(\"2020-11-22 20:00:00\",\"%Y-%m-%d %H:%M:%S\")\n",
    "test_3 = datetime.datetime.strptime(\"2020-11-22 23:00:00\",\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "#making sure the code works\n",
    "assert(test_1 < game_start_22nd)\n",
    "assert(game_start_22nd < test_2 and test_2 < game_end_22nd)\n",
    "assert(game_end_22nd < test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating game_tweets_22nd to hold all the tweets that happened during the game\n",
    "game_tweets_22nd = []\n",
    "\n",
    "for pairs in balt_vs_Titans :\n",
    "    time = pairs[0]\n",
    "    if (time > game_start_22nd and time < game_end_22nd) :\n",
    "        game_tweets_22nd.append(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ordering the list of tuples by date\n",
    "#this makes it go from beginning to end (instead of end to beginning)\n",
    "game_tweets_22nd = sorted(game_tweets_22nd, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the data only includes the tweets that happened during the game. Let's move onto to understand the text in the tweets. The best way to do this is by taking a look at the basic descriptive statistics of the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens =[]\n",
    "\n",
    "for pair in game_tweets:\n",
    "    tweet = pair[1]\n",
    "    tweet = [w for w in tweet.lower().split()]\n",
    "    tweet = [w for w in tweet if w.isalpha() and w not in sw]\n",
    "    clean_tokens.extend(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens_22nd =[]\n",
    "\n",
    "for pairs in game_tweets_22nd:\n",
    "    tweet = pairs[1]\n",
    "    tweet = [w for w in tweet.lower().split()]\n",
    "    tweet = [w for w in tweet if w.isalpha() and w not in sw]\n",
    "    clean_tokens_22nd.extend(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ravens vs. Patriots on 11/15/20 \n",
      "\n",
      "Number of tweets = 1467\n",
      "Tokens = 9281\n",
      "Average tokens per tweet = 6.3265167007498295\n",
      "Unique tokens = 2340\n",
      "Lexical diversity = 0.252\n",
      "Average token length = 5.32\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ravens vs. Patriots on 11/15/20 \\n\")\n",
    "print(f\"Number of tweets = {len(game_tweets)}\")\n",
    "print(f\"Tokens = {len(clean_tokens)}\")\n",
    "print(f\"Average tokens per tweet = {len(clean_tokens)/len(game_tweets)}\")\n",
    "print(f\"Unique tokens = {len(set(clean_tokens))}\")\n",
    "print(f\"Lexical diversity = {len(set(clean_tokens))/len(clean_tokens):.3f}\")\n",
    "\n",
    "#token length vector\n",
    "len_of_clean_tokens = [len(w) for w in clean_tokens]\n",
    "print(f\"Average token length = {np.mean(len_of_clean_tokens):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 most used tokens:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('game', 122),\n",
       " ('lamar', 114),\n",
       " ('get', 102),\n",
       " ('defense', 86),\n",
       " ('go', 84),\n",
       " ('like', 84),\n",
       " ('play', 75),\n",
       " ('jackson', 71),\n",
       " ('ravens', 66),\n",
       " ('run', 65),\n",
       " ('ball', 61),\n",
       " ('one', 60),\n",
       " ('team', 55),\n",
       " ('first', 53),\n",
       " ('need', 53),\n",
       " ('right', 53),\n",
       " ('going', 52),\n",
       " ('drive', 51),\n",
       " ('good', 49),\n",
       " ('win', 46)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Top 20 most used tokens:\")\n",
    "ravens_fd = FreqDist(clean_tokens)\n",
    "ravens_fd.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ravens vs. Titans on 11/22/20 \n",
      "\n",
      "Number of tweets = 1686\n",
      "Tokens = 10120\n",
      "Average tokens per tweet = 6.002372479240806\n",
      "Unique tokens = 2363\n",
      "Lexical diversity = 0.233\n",
      "Average token length = 5.26\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ravens vs. Titans on 11/22/20 \\n\")\n",
    "print(f\"Number of tweets = {len(game_tweets_22nd)}\")\n",
    "print(f\"Tokens = {len(clean_tokens_22nd)}\")\n",
    "print(f\"Average tokens per tweet = {len(clean_tokens_22nd)/len(game_tweets_22nd)}\")\n",
    "print(f\"Unique tokens = {len(set(clean_tokens_22nd))}\")\n",
    "print(f\"Lexical diversity = {len(set(clean_tokens_22nd))/len(clean_tokens_22nd):.3f}\")\n",
    "\n",
    "#token length vector\n",
    "len_of_clean_tokens_22nd = [len(w) for w in clean_tokens_22nd]\n",
    "print(f\"Average token length = {np.mean(len_of_clean_tokens_22nd):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 most used tokens:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('game', 129),\n",
       " ('get', 111),\n",
       " ('lamar', 108),\n",
       " ('go', 93),\n",
       " ('henry', 86),\n",
       " ('titans', 84),\n",
       " ('defense', 82),\n",
       " ('dobbins', 80),\n",
       " ('first', 78),\n",
       " ('like', 73),\n",
       " ('play', 72),\n",
       " ('good', 71),\n",
       " ('jackson', 67),\n",
       " ('td', 65),\n",
       " ('ravens', 64),\n",
       " ('ball', 63),\n",
       " ('need', 62),\n",
       " ('one', 59),\n",
       " ('field', 59),\n",
       " ('derrick', 58)]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Top 20 most used tokens:\")\n",
    "\n",
    "ravens_fd = FreqDist(clean_tokens_22nd)\n",
    "ravens_fd.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main difference between the two games is the number of tweets. The Ravens vs. Titans game had almost 200 more tweets than when the Ravens played the Patriots. This was surpising because the game against the Patriots was in primetime. I would assume more people would be watching the Sunday Night Football game since it is the only game on at that time. The game against the Titans was an 11:00 AM (MT time) game. This time slot also has a number of other games on. One reason the Ravens vs. Titans game might have had more tweets is because the game went into overtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There really isn't significant differences in the other statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As far as the top 20 most used tokens for each game, there are fairly similar. The most popular player for the Ravens, Lamar Jackson, shows up in both. The words: game, get, go, defense, first, like, play, ravens, ball, one, good also show up in both. Obviously, these are going to be pretty similar.\n",
    "\n",
    "Derrick Henry shows up in the Ravens vs Titans game. He is the best player on the Titans.\n",
    "\n",
    "Dobbins also shows up in this game. He is the Ravens rookie running back who had a break out game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving on to Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bring in the text file with sentiment scores for each word\n",
    "sentiment_scores = {}\n",
    "\n",
    "with open(\"tidytext_sentiments.txt\",'r') as infile :\n",
    "    next(infile)\n",
    "    for line in infile.readlines() :\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        if line[1] == \"positive\" :\n",
    "            sentiment_scores[line[0]] = 1\n",
    "        else :\n",
    "            sentiment_scores[line[0]] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is only taking tokens, can it write out idx, time, score of individual tweet?????\n",
    "\n",
    "#trying to have a running counter of sentiment\n",
    "#+1 for positive, -1 for negative\n",
    "\n",
    "running_counter = [0] * len(clean_tokens)\n",
    "current_score = 0 \n",
    "\n",
    "for idx, word in enumerate(clean_tokens) :\n",
    "    if word in sentiment_scores :\n",
    "        current_score += sentiment_scores[word.lower()]\n",
    "    \n",
    "    running_counter[idx] = current_score\n",
    "    \n",
    "    #if idx > 100 :\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing out idx, sentiment score counter to a text file\n",
    "with open(\"#ravens_scores.txt\",'w') as ofile :\n",
    "    ofile.write(\"word\\tscore\\n\")\n",
    "    for idx, score in enumerate(running_counter) :\n",
    "        ofile.write(\"\\t\".join([str(idx+1),str(score)]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the next game..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probably don't need this twice\n",
    "#bring in the text file with sentiment scores for each word\n",
    "sentiment_scores = {}\n",
    "\n",
    "with open(\"tidytext_sentiments.txt\",'r') as infile :\n",
    "    next(infile)\n",
    "    for line in infile.readlines() :\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        if line[1] == \"positive\" :\n",
    "            sentiment_scores[line[0]] = 1\n",
    "        else :\n",
    "            sentiment_scores[line[0]] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_counter = [0] * len(clean_tokens_22nd)\n",
    "current_score = 0 \n",
    "\n",
    "for idx, word in enumerate(clean_tokens_22nd) :\n",
    "    if word in sentiment_scores :\n",
    "        current_score += sentiment_scores[word.lower()]\n",
    "    \n",
    "    running_counter[idx] = current_score\n",
    "    \n",
    "    #if idx > 100 :\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing out idx, sentiment score counter to a text file\n",
    "with open(\"#ravens_vs_titans_scores.txt\",'w') as ofile :\n",
    "    ofile.write(\"word\\tscore\\n\")\n",
    "    for idx, score in enumerate(running_counter) :\n",
    "        ofile.write(\"\\t\".join([str(idx+1),str(score)]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ravens vs. Patriots - 11/15/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/SS_vsPats.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sunday Night Football game between the Ravens and the Patriots got off to a slow start. It took until the 2nd quarter for the Ravens to strike first. Then the game was back and forth up until halftime. After halftime, the Patriots jumped out to a 13 point lead. The Ravens score at the end of the 3rd to bring the game closer. The 4th quarter was a defensive battle. It was lightly raining the whole game which may have played a factor. The Ravens had one more chance at the end to go the length of the field to score and win the game. As the Ravens took the field for the last drive, the light rain turned into an absolute downpour. The Ravens would eventually turn the ball over on downs which would lead to them losing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/win_probPats.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot from ESPN shows the win probability for each team in real time. When the colored line is closest to the middle (50%), each team has a win probability of 50%. That is when the game is the closest. The farther the line moves away from the middle, the team's win probability gets closer to 100%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/vsPats.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentiment plot of #Ravens tweets during the SNF game show the back and forth flow that played out. The sentiment is positive at the start even though neither team scores in the first quarter. The plot shows the up-and-down flow of the 1st half where each team trades scores. Around halftime, the sentiment is positive for people tweeting #Ravens. The win probability is also still in favor of the Ravens. The Patriots come out after halftime and score twice, pushing their lead to 13 points. The win probability starts to go in the Patriots direction. The sentiment starts to drop as well signaling negativity in the #Ravens tweets. \n",
    "\n",
    "The win probability starts to drift closer to 50% as the game goes on. This is signaling the Ravens still have a chance. I'm guessing this is because the Ravens scored at the end of the 3rd. There is also a slight rise in sentiment. The Ravens have one last chance on their last drive, but they can't pull through. The win probability goes to 100% for the Patriots. The sentiment at the end is up and down. This must be signaling some optimism before the Ravens finally lose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ravens vs. Titans - 11/22/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/SS_vsTitans.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Ravens next opponent was the Tennessee Titans. The Ravens came out playing great this game and jumped out to a large lead going into halftime. The Titans battled back and eventually tied the game at the end of regulation which would send the game to overtime. In OT, the Titans running back scored the game winning touchdown, ending the game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/win_probTitans.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The win probability plot for this game is easier to see because of the difference in color."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/vsTitans.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentiment plot for this game shows a positive trend throughout. There are plenty of dips, up-and-down, in sentiment, but no large drops like in the last game. This was very surprising because the Titans scored 14 points straight towards the end of the game. Surely, I thought there would be negativity in the #Ravens tweets during this time. The sentiment plot still follows the win probability plot. The Ravens were favored to win almost the whole game until the end. At the end of the sentiment plot, there is a slight drop in sentiment. This is right when the Titans start to gain control of the game and see there win probability rise. \n",
    "\n",
    "If I extended the plot a little further to include #Ravens tweets after the game, we might see the senitment continue to drop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentiment of an NFL team's hashtag definitely shows the ups-and-downs that teams, along with their fans, go through during the course of a game. The sentiment plot of the first game analzyed between the Ravens and Patriots tracked very well with the game flow and win probability plot from ESPN. The second game, between the Ravens and Titans, again showed sentiment scores rising and falling. The ups-and-downs weren't nearly as extreme as the first game, making it hard to tell if sentiment scores truly compared to win probability.\n",
    "\n",
    "I was really lucky to choose a team like the Baltimore Ravens who had two back to back games that were super close. \n",
    "A wider variety of games may be necessary to truly test if sentiment scores follow win probability. From the analysis of these two games, it definitely showed it is worth testing more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis was an idea that I came into Text Mining excited to try out. Sentiment analysis can be noisy in small scales but fairly accurate in large scales. Both of the games had around 1,500 tweets which may not be enough to be considered large scale. \n",
    "\n",
    "Another problem with tweets from Twitter is people tend to be sarcastic when they post. It is almost impossible for sentiment analysis to pick up on that.\n",
    "\n",
    "One last problem that may have occurred, is some of the tweets include hashtags from both teams (#Ravens, #Titans). Therefore, there could have been Titans fans tweeting positive things about their team but including the other teams hashtag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * scoring summaries and win probability plots come from ESPN.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
